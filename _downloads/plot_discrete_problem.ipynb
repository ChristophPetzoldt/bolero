{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Discrete Problem\n\n\nA simple problem with a discrete state and action space is solved with\na tabular reinforcement learning algorithm. The plot shows the obtained return\nfor each episode. Successful episodes terminate with the return 1, otherwise\nthe return is 0. The learning process is stopped when the value function\nconverged.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print(__doc__)\n\nimport matplotlib.pyplot as plt\nfrom bolero.environment import OpenAiGym\nfrom bolero.behavior_search import MonteCarloRL\nfrom bolero.controller import Controller\n\n\nenv = OpenAiGym(\"FrozenLake-v0\", render=False, seed=1)\nenv.init()\nbs = MonteCarloRL(env.get_discrete_action_space(), random_state=1)\nctrl = Controller(environment=env, behavior_search=bs, n_episodes=10000,\n                  finish_after_convergence=True)\nrewards = ctrl.learn()\n\nplt.figure()\nax = plt.subplot(111)\nax.set_title(\"Learning progress\")\nax.plot(rewards)\nax.set_xlabel(\"Episode\")\nax.set_ylabel(\"Reward\")\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}